{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thrones2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Â© Yuriy Guts, 2016"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using only the raw text of [A Song of Ice and Fire](https://en.wikipedia.org/wiki/A_Song_of_Ice_and_Fire), we'll derive and explore the semantic properties of its words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import codecs\n",
    "import glob\n",
    "import logging\n",
    "import multiprocessing\n",
    "import os\n",
    "import pprint\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\similarities\\__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import gensim.models.word2vec as w2v\n",
    "import sklearn.manifold\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Set up logging**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Download NLTK tokenizer models (only the first time)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to C:\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load books from files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "book_filenames = sorted(glob.glob(\"./data/*.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found books:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['./data\\\\got1.txt',\n",
       " './data\\\\got2.txt',\n",
       " './data\\\\got3.txt',\n",
       " './data\\\\got4.txt',\n",
       " './data\\\\got5.txt']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Found books:\")\n",
    "book_filenames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Combine the books into one string**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading './data\\got1.txt'...\n",
      "Corpus is now 1787941 characters long\n",
      "\n",
      "Reading './data\\got2.txt'...\n",
      "Corpus is now 4110003 characters long\n",
      "\n",
      "Reading './data\\got3.txt'...\n",
      "Corpus is now 6452402 characters long\n",
      "\n",
      "Reading './data\\got4.txt'...\n",
      "Corpus is now 8185413 characters long\n",
      "\n",
      "Reading './data\\got5.txt'...\n",
      "Corpus is now 9811978 characters long\n",
      "\n"
     ]
    }
   ],
   "source": [
    "corpus_raw = u\"\"\n",
    "for book_filename in book_filenames:\n",
    "    print(\"Reading '{0}'...\".format(book_filename))\n",
    "    with codecs.open(book_filename, \"r\", \"utf-8\") as book_file:\n",
    "        corpus_raw += book_file.read()\n",
    "    print(\"Corpus is now {0} characters long\".format(len(corpus_raw)))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Split the corpus into sentences**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "raw_sentences = tokenizer.tokenize(corpus_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#convert into a list of words\n",
    "#rtemove unnnecessary,, split into words, no hyphens\n",
    "#list of words\n",
    "def sentence_to_wordlist(raw):\n",
    "    clean = re.sub(\"[^a-zA-Z]\",\" \", raw)\n",
    "    words = clean.split()\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#sentence where each word is tokenized\n",
    "sentences = []\n",
    "for raw_sentence in raw_sentences:\n",
    "    if len(raw_sentence) > 0:\n",
    "        sentences.append(sentence_to_wordlist(raw_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heraldic crest by Virginia Norey.\n",
      "['Heraldic', 'crest', 'by', 'Virginia', 'Norey']\n"
     ]
    }
   ],
   "source": [
    "print(raw_sentences[5])\n",
    "print(sentence_to_wordlist(raw_sentences[5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The book corpus contains 1,818,103 tokens\n"
     ]
    }
   ],
   "source": [
    "token_count = sum([len(sentence) for sentence in sentences])\n",
    "print(\"The book corpus contains {0:,} tokens\".format(token_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#ONCE we have vectors\n",
    "#step 3 - build model\n",
    "#3 main tasks that vectors help with\n",
    "#DISTANCE, SIMILARITY, RANKING\n",
    "\n",
    "# Dimensionality of the resulting word vectors.\n",
    "#more dimensions, more computationally expensive to train\n",
    "#but also more accurate\n",
    "#more dimensions = more generalized\n",
    "num_features = 300\n",
    "# Minimum word count threshold.\n",
    "min_word_count = 3\n",
    "\n",
    "# Number of threads to run in parallel.\n",
    "#more workers, faster we train\n",
    "num_workers = multiprocessing.cpu_count()\n",
    "\n",
    "# Context window length.\n",
    "context_size = 7\n",
    "\n",
    "# Downsample setting for frequent words.\n",
    "#0 - 1e-5 is good for this\n",
    "downsampling = 1e-3\n",
    "\n",
    "# Seed for the RNG, to make the results reproducible.\n",
    "#random number generator\n",
    "#deterministic, good for debugging\n",
    "seed = 1\n",
    "\n",
    "# Number of iterations theneural network is trained\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-24 16:49:54,611 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=0, vector_size=300, alpha=0.025)', 'datetime': '2021-10-24T16:49:54.610724', 'gensim': '4.0.1', 'python': '3.8.8 (default, Apr 13 2021, 15:08:03) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "thrones2vec = w2v.Word2Vec(\n",
    "    sg=1,\n",
    "    seed=seed,\n",
    "    workers=num_workers,\n",
    "    vector_size=num_features,\n",
    "    min_count=min_word_count,\n",
    "    window=context_size,\n",
    "    sample=downsampling,\n",
    "    epochs= epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-24 16:49:54,642 : INFO : collecting all words and their counts\n",
      "2021-10-24 16:49:54,642 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2021-10-24 16:49:54,666 : INFO : PROGRESS: at sentence #10000, processed 140984 words, keeping 10280 word types\n",
      "2021-10-24 16:49:54,689 : INFO : PROGRESS: at sentence #20000, processed 279730 words, keeping 13558 word types\n",
      "2021-10-24 16:49:54,717 : INFO : PROGRESS: at sentence #30000, processed 420336 words, keeping 16598 word types\n",
      "2021-10-24 16:49:54,742 : INFO : PROGRESS: at sentence #40000, processed 556581 words, keeping 18324 word types\n",
      "2021-10-24 16:49:54,765 : INFO : PROGRESS: at sentence #50000, processed 686247 words, keeping 19714 word types\n",
      "2021-10-24 16:49:54,790 : INFO : PROGRESS: at sentence #60000, processed 828497 words, keeping 21672 word types\n",
      "2021-10-24 16:49:54,817 : INFO : PROGRESS: at sentence #70000, processed 973830 words, keeping 23093 word types\n",
      "2021-10-24 16:49:54,843 : INFO : PROGRESS: at sentence #80000, processed 1114967 words, keeping 24252 word types\n",
      "2021-10-24 16:49:54,870 : INFO : PROGRESS: at sentence #90000, processed 1260481 words, keeping 26007 word types\n",
      "2021-10-24 16:49:54,894 : INFO : PROGRESS: at sentence #100000, processed 1393203 words, keeping 26884 word types\n",
      "2021-10-24 16:49:54,921 : INFO : PROGRESS: at sentence #110000, processed 1532150 words, keeping 27809 word types\n",
      "2021-10-24 16:49:54,948 : INFO : PROGRESS: at sentence #120000, processed 1680961 words, keeping 28486 word types\n",
      "2021-10-24 16:49:54,972 : INFO : collected 29026 word types from a corpus of 1818103 raw words and 128868 sentences\n",
      "2021-10-24 16:49:54,973 : INFO : Creating a fresh vocabulary\n",
      "2021-10-24 16:49:55,027 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=3 retains 17277 unique words (59.52249707159099%% of original 29026, drops 11749)', 'datetime': '2021-10-24T16:49:55.027101', 'gensim': '4.0.1', 'python': '3.8.8 (default, Apr 13 2021, 15:08:03) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'prepare_vocab'}\n",
      "2021-10-24 16:49:55,027 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=3 leaves 1802699 word corpus (99.15274327142082%% of original 1818103, drops 15404)', 'datetime': '2021-10-24T16:49:55.027101', 'gensim': '4.0.1', 'python': '3.8.8 (default, Apr 13 2021, 15:08:03) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'prepare_vocab'}\n",
      "2021-10-24 16:49:55,112 : INFO : deleting the raw counts dictionary of 29026 items\n",
      "2021-10-24 16:49:55,113 : INFO : sample=0.001 downsamples 50 most-common words\n",
      "2021-10-24 16:49:55,114 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 1404424.1738617136 word corpus (77.9%% of prior 1802699)', 'datetime': '2021-10-24T16:49:55.114180', 'gensim': '4.0.1', 'python': '3.8.8 (default, Apr 13 2021, 15:08:03) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'prepare_vocab'}\n",
      "2021-10-24 16:49:55,245 : INFO : estimated required memory for 17277 words and 300 dimensions: 50103300 bytes\n",
      "2021-10-24 16:49:55,246 : INFO : resetting layer weights\n",
      "2021-10-24 16:49:55,263 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2021-10-24T16:49:55.263317', 'gensim': '4.0.1', 'python': '3.8.8 (default, Apr 13 2021, 15:08:03) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'build_vocab'}\n"
     ]
    }
   ],
   "source": [
    "thrones2vec.build_vocab(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec vocabulary length: 17277\n"
     ]
    }
   ],
   "source": [
    "print(\"Word2Vec vocabulary length:\", len(thrones2vec.wv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Start training, this might take a minute or two...**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-24 16:49:55,340 : INFO : Word2Vec lifecycle event {'msg': 'training model with 16 workers on 17277 vocabulary and 300 features, using sg=1 hs=0 sample=0.001 negative=5 window=7', 'datetime': '2021-10-24T16:49:55.340386', 'gensim': '4.0.1', 'python': '3.8.8 (default, Apr 13 2021, 15:08:03) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'train'}\n",
      "2021-10-24 16:49:56,391 : INFO : EPOCH 1 - PROGRESS: at 4102.94% words, 535677 words/s, in_qsize 31, out_qsize 0\n",
      "2021-10-24 16:49:57,395 : INFO : EPOCH 1 - PROGRESS: at 8727.02% words, 575379 words/s, in_qsize 31, out_qsize 0\n",
      "2021-10-24 16:49:57,631 : INFO : worker thread finished; awaiting finish of 15 more threads\n",
      "2021-10-24 16:49:57,647 : INFO : worker thread finished; awaiting finish of 14 more threads\n",
      "2021-10-24 16:49:57,652 : INFO : worker thread finished; awaiting finish of 13 more threads\n",
      "2021-10-24 16:49:57,654 : INFO : worker thread finished; awaiting finish of 12 more threads\n",
      "2021-10-24 16:49:57,655 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2021-10-24 16:49:57,656 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2021-10-24 16:49:57,658 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2021-10-24 16:49:57,661 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2021-10-24 16:49:57,671 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2021-10-24 16:49:57,673 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2021-10-24 16:49:57,675 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2021-10-24 16:49:57,712 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2021-10-24 16:49:57,717 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-10-24 16:49:57,719 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-10-24 16:49:57,720 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-10-24 16:49:57,734 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-10-24 16:49:57,734 : INFO : EPOCH - 1 : training on 1818103 raw words (1405011 effective words) took 2.4s, 593566 effective words/s\n",
      "2021-10-24 16:49:57,735 : WARNING : EPOCH - 1 : supplied raw word count (1818103) did not equal expected count (17277)\n",
      "2021-10-24 16:49:57,735 : INFO : Word2Vec lifecycle event {'msg': 'training on 1818103 raw words (1405011 effective words) took 2.4s, 586813 effective words/s', 'datetime': '2021-10-24T16:49:57.735581', 'gensim': '4.0.1', 'python': '3.8.8 (default, Apr 13 2021, 15:08:03) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'train'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1405011, 1818103)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thrones2vec.train(sentences,total_words=(len(thrones2vec.wv)), epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save to file, can be useful later**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(\"trained\"):\n",
    "    os.makedirs(\"trained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-24 16:49:57,801 : INFO : Word2Vec lifecycle event {'fname_or_handle': 'trained\\\\thrones2vec.w2v', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2021-10-24T16:49:57.801664', 'gensim': '4.0.1', 'python': '3.8.8 (default, Apr 13 2021, 15:08:03) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'saving'}\n",
      "2021-10-24 16:49:57,802 : INFO : not storing attribute cum_table\n",
      "2021-10-24 16:49:57,836 : INFO : saved trained\\thrones2vec.w2v\n"
     ]
    }
   ],
   "source": [
    "thrones2vec.save(os.path.join(\"trained\", \"thrones2vec.w2v\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-24 16:49:57,865 : INFO : loading Word2Vec object from trained\\thrones2vec.w2v\n",
      "2021-10-24 16:49:57,882 : INFO : loading wv recursively from trained\\thrones2vec.w2v.wv.* with mmap=None\n",
      "2021-10-24 16:49:57,883 : INFO : setting ignored attribute cum_table to None\n",
      "2021-10-24 16:49:58,008 : INFO : Word2Vec lifecycle event {'fname': 'trained\\\\thrones2vec.w2v', 'datetime': '2021-10-24T16:49:58.008804', 'gensim': '4.0.1', 'python': '3.8.8 (default, Apr 13 2021, 15:08:03) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'loaded'}\n"
     ]
    }
   ],
   "source": [
    "thrones2vec = w2v.Word2Vec.load(os.path.join(\"trained\", \"thrones2vec.w2v\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compress the word vectors into 2D space and plot them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#my video - how to visualize a dataset easily\n",
    "tsne = sklearn.manifold.TSNE(n_components=2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_word_vectors_matrix = thrones2vec.wv.vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train t-SNE, this could take a minute or two...**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_word_vectors_matrix_2d = tsne.fit_transform(all_word_vectors_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot the big picture**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Key '0.17041753232479095' not present\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-baaff5e0fcc2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m     [\n\u001b[0;32m      4\u001b[0m         \u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcoords\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcoords\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         for word, coords in [\n\u001b[0m\u001b[0;32m      6\u001b[0m             \u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mall_word_vectors_matrix_2d\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mthrones2vec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mthrones2vec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-27-baaff5e0fcc2>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcoords\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcoords\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         for word, coords in [\n\u001b[1;32m----> 6\u001b[1;33m             \u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mall_word_vectors_matrix_2d\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mthrones2vec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mthrones2vec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         ]\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key_or_keys)\u001b[0m\n\u001b[0;32m    379\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey_or_keys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    380\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 381\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mvstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkey_or_keys\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    382\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    383\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    379\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey_or_keys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    380\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 381\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mvstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkey_or_keys\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    382\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    383\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36mget_vector\u001b[1;34m(self, key, norm)\u001b[0m\n\u001b[0;32m    420\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    421\u001b[0m         \"\"\"\n\u001b[1;32m--> 422\u001b[1;33m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    423\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnorm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    424\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfill_norms\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36mget_index\u001b[1;34m(self, key, default)\u001b[0m\n\u001b[0;32m    394\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mdefault\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    395\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 396\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Key '{key}' not present\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    397\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    398\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"Key '0.17041753232479095' not present\""
     ]
    }
   ],
   "source": [
    "#plot point in 2d space\n",
    "points = pd.DataFrame(\n",
    "    [\n",
    "        (word, coords[0], coords[1])\n",
    "        for word, coords in [\n",
    "            (word, all_word_vectors_matrix_2d[thrones2vec.wv[word].index])\n",
    "            for word in thrones2vec.wv\n",
    "        ]\n",
    "    ],\n",
    "    columns=[\"word\", \"x\", \"y\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'points' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-162-17c1f1e79cf0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpoints\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'points' is not defined"
     ]
    }
   ],
   "source": [
    "points.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.set_context(\"poster\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'points' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-188-42c36ae8f15c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpoints\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"x\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"y\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m12\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'points' is not defined"
     ]
    }
   ],
   "source": [
    "points.plot.scatter(\"x\", \"y\", s=10, figsize=(20, 12))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Zoom in to some interesting places**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_region(x_bounds, y_bounds):\n",
    "    slice = points[\n",
    "        (x_bounds[0] <= points.x) &\n",
    "        (points.x <= x_bounds[1]) & \n",
    "        (y_bounds[0] <= points.y) &\n",
    "        (points.y <= y_bounds[1])\n",
    "    ]\n",
    "    \n",
    "    ax = slice.plot.scatter(\"x\", \"y\", s=35, figsize=(10, 8))\n",
    "    for i, point in slice.iterrows():\n",
    "        ax.text(point.x + 0.005, point.y + 0.005, point.word, fontsize=11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**People related to Kingsguard ended up together**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plot_region' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-167-3606d96f6cad>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplot_region\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_bounds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m4.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4.2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_bounds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'plot_region' is not defined"
     ]
    }
   ],
   "source": [
    "plot_region(x_bounds=(4.0, 4.2), y_bounds=(-0.5, -0.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Food products are grouped nicely as well. Aerys (The Mad King) being close to \"roasted\" also looks sadly correct**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plot_region' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-495-635bb73d3e2c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplot_region\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_bounds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_bounds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'plot_region' is not defined"
     ]
    }
   ],
   "source": [
    "plot_region(x_bounds=(0, 1), y_bounds=(4, 4.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore semantic similarities between book characters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Words closest to the given word**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Renly', 0.9996801614761353),\n",
       " ('these', 0.9996761083602905),\n",
       " ('Melisandre', 0.9996749758720398),\n",
       " ('Arryn', 0.9996713399887085),\n",
       " ('gave', 0.999670147895813),\n",
       " ('hard', 0.9996687173843384),\n",
       " ('us', 0.9996671080589294),\n",
       " ('Sansa', 0.9996653199195862),\n",
       " ('again', 0.9996653199195862),\n",
       " ('look', 0.9996640682220459)]"
      ]
     },
     "execution_count": 494,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thrones2vec.wv.most_similar(\"Stark\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Tyrion', 0.9991716146469116),\n",
       " ('looked', 0.9991581439971924),\n",
       " ('green', 0.9991570115089417),\n",
       " ('upon', 0.9991549253463745),\n",
       " ('past', 0.9991487860679626),\n",
       " ('felt', 0.9991335272789001),\n",
       " ('small', 0.9991294145584106),\n",
       " ('days', 0.9991273283958435),\n",
       " ('three', 0.9991270303726196),\n",
       " ('declared', 0.9991257786750793)]"
      ]
     },
     "execution_count": 493,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thrones2vec.wv.most_similar(\"Aerys\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('life', 0.998898446559906),\n",
       " ('first', 0.9988821744918823),\n",
       " ('just', 0.9988820552825928),\n",
       " ('stood', 0.9988740682601929),\n",
       " ('thousand', 0.9988735318183899),\n",
       " ('Starks', 0.9988728165626526),\n",
       " ('beside', 0.9988706111907959),\n",
       " ('us', 0.9988702535629272),\n",
       " ('As', 0.9988590478897095),\n",
       " ('A', 0.998852014541626)]"
      ]
     },
     "execution_count": 492,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thrones2vec.wv.most_similar(\"direwolf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Linear relationships between word pairs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nearest_similarity_cosmul(start1, end1, end2):\n",
    "    similarities = thrones2vec.wv.most_similar_cosmul(\n",
    "        positive=[end2, start1],\n",
    "        negative=[end1]\n",
    "    )\n",
    "    start2 = similarities[0][0]\n",
    "    print(\"{start1} is related to {end1}, as {start2} is related to {end2}\".format(**locals()))\n",
    "    return start2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stark is related to Winterfell, as us is related to Riverrun\n",
      "Jaime is related to sword, as keep is related to wine\n",
      "Arya is related to Nymeria, as ask is related to dragons\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'ask'"
      ]
     },
     "execution_count": 490,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nearest_similarity_cosmul(\"Stark\", \"Winterfell\", \"Riverrun\")\n",
    "nearest_similarity_cosmul(\"Jaime\", \"sword\", \"wine\")\n",
    "nearest_similarity_cosmul(\"Arya\", \"Nymeria\", \"dragons\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 9.16706678e-03,  9.12458077e-03,  4.65888577e-03,  7.51225685e-04,\n",
       "        6.51571061e-03, -7.47678569e-03, -4.84486949e-03,  1.35378176e-02,\n",
       "        3.83791723e-03, -2.35543214e-03,  2.62629124e-03, -6.49313908e-03,\n",
       "       -3.30254389e-03, -1.95715320e-03, -6.17279066e-03, -5.57435956e-03,\n",
       "        4.42027487e-03,  5.64179849e-03,  3.05657554e-03,  7.53045315e-04,\n",
       "       -6.16001943e-03, -1.40100403e-03,  7.15341792e-03, -1.41804898e-03,\n",
       "        5.42204408e-03, -2.21430114e-03, -7.24606449e-03,  6.87845191e-03,\n",
       "       -1.77125365e-03, -4.65646852e-03,  2.26242654e-03,  2.94878823e-03,\n",
       "       -3.34855937e-03, -2.01449939e-03, -4.56418470e-03,  1.05869994e-02,\n",
       "        3.98758333e-03, -1.78518065e-03, -6.45005424e-03,  9.89859644e-03,\n",
       "       -3.78285232e-03,  5.74525865e-03, -8.68281524e-04, -7.89556559e-03,\n",
       "       -1.03812362e-03, -2.31644325e-03, -4.25671024e-05,  2.29795332e-05,\n",
       "        6.02236297e-03,  5.98191097e-03,  6.36213645e-03, -3.14699207e-03,\n",
       "       -2.73662317e-03,  2.33677030e-03, -3.57200275e-03,  8.11485574e-03,\n",
       "        2.15883600e-03,  5.95631497e-03, -2.63940613e-03,  6.50383020e-03,\n",
       "       -1.54730119e-03,  7.02357525e-03, -2.25530891e-03,  3.75608145e-03,\n",
       "       -4.17241035e-03,  1.84861454e-03,  6.16150862e-03,  3.24753067e-03,\n",
       "       -2.22682371e-03, -5.58231222e-05, -2.74279341e-03,  3.37087410e-03,\n",
       "       -2.68835138e-04, -5.96225355e-03,  3.46715120e-03,  4.08792030e-03,\n",
       "        1.34265760e-03, -7.22563127e-03, -5.62488893e-03,  6.96764933e-03,\n",
       "       -1.06417090e-02,  4.15889517e-05,  1.06831698e-03,  5.69185102e-03,\n",
       "       -1.92915578e-03,  6.98674936e-03, -9.78660421e-04,  1.95279787e-03,\n",
       "       -7.10248202e-03,  1.28759956e-02,  4.62924177e-03, -7.68401241e-03,\n",
       "        4.71190317e-03,  2.20293482e-03, -1.15267735e-03,  3.26707470e-03,\n",
       "        9.45920032e-03, -5.89333184e-04,  1.52071915e-03, -1.87048409e-03,\n",
       "       -1.09399883e-02,  2.78359675e-03,  1.23235362e-03,  3.24437558e-03,\n",
       "        2.67386506e-03, -1.00378525e-02,  3.89407098e-04,  1.08411745e-03,\n",
       "        1.05700141e-03, -4.75393841e-03, -5.02869207e-03, -2.80157197e-03,\n",
       "       -1.29332161e-03,  6.78973505e-03,  6.40655344e-04,  9.27524362e-03,\n",
       "        1.49910513e-03,  3.04566813e-03,  4.64149285e-03, -1.36157321e-02,\n",
       "        5.62479999e-03,  5.70098590e-03,  1.17659485e-02,  8.59410284e-05,\n",
       "       -2.72408733e-03,  7.89242703e-03,  4.41112462e-03, -2.18965765e-03,\n",
       "       -2.83074868e-03,  1.92978070e-03,  2.25892221e-03,  6.66807828e-05,\n",
       "        1.05667661e-03, -7.88502768e-03,  3.40520195e-03, -5.00893034e-03,\n",
       "       -3.46659240e-03,  2.58894102e-03, -4.85234102e-03, -8.74109659e-03,\n",
       "        2.56563770e-03, -5.55024110e-03, -5.79967443e-03,  1.15351668e-02,\n",
       "        1.43145313e-02,  2.65366107e-04, -3.67960869e-03, -1.23050530e-02,\n",
       "        3.79777839e-03,  1.79684197e-03, -4.76238038e-03, -1.03371814e-02,\n",
       "       -4.45870776e-03, -5.46453893e-03,  8.90467316e-04,  7.34589342e-03,\n",
       "       -1.21062286e-02,  1.81260519e-03, -4.28010896e-03,  5.44147892e-03,\n",
       "        3.23086279e-04,  4.54759039e-03, -7.98498653e-03,  4.06410964e-03,\n",
       "        3.28929140e-03,  7.16798357e-04, -1.10600004e-03, -3.62789771e-03,\n",
       "        3.50437919e-03,  5.13985008e-03, -2.31485418e-03, -4.94847028e-03,\n",
       "        2.77357199e-03,  6.12341100e-03,  5.88083500e-03,  4.37928538e-04,\n",
       "       -7.71585386e-03, -8.25164560e-03,  1.88615161e-03, -5.56070777e-03,\n",
       "       -1.16931405e-02,  6.74991682e-03, -5.46581950e-03, -1.33610563e-03,\n",
       "        8.64053494e-04, -1.45541434e-03,  8.78368784e-03,  1.01247272e-02,\n",
       "        6.65076263e-03, -1.12798270e-02,  3.28754191e-03, -3.56065342e-03,\n",
       "       -1.07786069e-02,  3.37515725e-03,  2.61431118e-03, -7.76693644e-03,\n",
       "       -6.04929286e-04, -6.01598946e-03, -8.94329103e-04,  6.95469137e-03,\n",
       "       -1.42514743e-02,  3.83753679e-04, -3.20213544e-03, -1.00223841e-02,\n",
       "        1.14920205e-02,  1.01124775e-03,  2.21857126e-03,  2.53208517e-03,\n",
       "       -3.00491485e-03,  9.24044616e-06, -3.02433246e-03, -5.51077584e-03,\n",
       "       -3.83934239e-03,  6.12932781e-04,  8.89830384e-03, -8.04016832e-03,\n",
       "       -2.59944913e-03, -1.12241944e-02, -1.33364676e-02, -6.51815161e-03,\n",
       "       -4.65447642e-03, -4.29781387e-03,  2.93337740e-03,  3.55782715e-04,\n",
       "        6.25126064e-04, -6.44634850e-03,  8.01916048e-03, -3.29458411e-03,\n",
       "       -5.66796260e-03,  3.56917805e-03,  2.87017087e-03, -4.60012117e-03,\n",
       "       -4.36298735e-03,  8.40783305e-03, -9.07784421e-03,  1.98449078e-03,\n",
       "        1.40581978e-03,  3.75045044e-03, -5.06727584e-03, -7.41729327e-03,\n",
       "        6.59766898e-04, -7.12844869e-03,  3.41281085e-03,  3.71900597e-03,\n",
       "        7.57252611e-03, -1.46805693e-03, -5.11853816e-03,  5.45652397e-03,\n",
       "        1.38737331e-03, -2.44739116e-03, -3.64883477e-03,  1.58051297e-03,\n",
       "        8.52840859e-03,  5.28111821e-03, -4.78870561e-03, -4.91292868e-03,\n",
       "        8.77580699e-03,  4.98222187e-04, -8.61520134e-03, -2.01700139e-03,\n",
       "        2.68438994e-03, -1.56764989e-03,  4.69854381e-03, -6.31404342e-03,\n",
       "       -8.87414161e-03, -1.21183775e-03,  5.03479503e-03,  3.16988211e-03,\n",
       "       -5.78712812e-03,  8.06611776e-03, -3.01375287e-03, -2.20894907e-03,\n",
       "       -4.16134158e-03,  5.84480446e-03, -1.13773230e-03, -6.14428613e-03,\n",
       "        6.46796869e-03,  5.91784948e-03, -9.41545237e-04, -7.09835673e-03,\n",
       "        5.63594094e-03,  8.33406870e-04,  1.48179906e-03,  4.08410182e-04,\n",
       "       -2.18454353e-03, -1.79512275e-03, -8.71351454e-03,  8.20986275e-03,\n",
       "        2.58427928e-03, -2.36630789e-04,  4.09648241e-03,  9.77592543e-03,\n",
       "        3.49611044e-03, -4.46117902e-03,  3.17285792e-03,  1.09933410e-02,\n",
       "        5.08634187e-03, -5.64427907e-03, -3.02710617e-03,  4.17555093e-05],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1 Print the one-hot-vector for Arryn\n",
    "thrones2vec.wv[\"Arry\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are: 17277 Vetors\n"
     ]
    }
   ],
   "source": [
    "#2\n",
    "print(\"There are:\", len(thrones2vec.wv),\"Vetors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'thrones2vec' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-da5ebdd2a41a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mnumber_of_similarities\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m7\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mword\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Lannister\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"The {} most similar words for {} are:\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumber_of_similarities\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthrones2vec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtopn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnumber_of_similarities\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'thrones2vec' is not defined"
     ]
    }
   ],
   "source": [
    "#3\n",
    "number_of_similarities = 7\n",
    "word = \"Lannister\"\n",
    "print(\"The {} most similar words for {} are:\".format(number_of_similarities,word), thrones2vec.wv.most_similar(word,topn=number_of_similarities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity of Jon and Ygritte 0.9951668\n"
     ]
    }
   ],
   "source": [
    "#4\n",
    "word1 = \"Jon\"\n",
    "word2 = \"Ygritte\"\n",
    "print(\"Similarity of {} and {}\".format(word1,word2,), thrones2vec.wv.similarity(word1, word2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9014625549316406\n",
      "['Hodor', 'that', 'was', 'all', 'he', 'ever', 'said'] ['Hold', 'the', 'door']\n",
      "Similarity of Jon and Snow 0.99918425\n"
     ]
    }
   ],
   "source": [
    "#5\n",
    "sentence1 = [\"Hodor\", \"that\", \"was\", \"all\", \"he\", \"ever\", \"said\"]\n",
    "sentence2 = [\"Hold\", \"the\", \"door\"]\n",
    "sum_of_similarities = 0\n",
    "\n",
    "for x in sentence1:\n",
    "    for y in sentence2:\n",
    "        sum_of_similarities += thrones2vec.wv.similarity(x,y)\n",
    "\n",
    "print(sum_of_similarities/(len(sentence1)*len(sentence2)))\n",
    "print(sentence1,sentence2)\n",
    "\n",
    "word1 = \"Jon\"\n",
    "word2 = \"Snow\"\n",
    "print(\"Similarity of {} and {}\".format(word1,word2,), thrones2vec.wv.similarity(word1, word2))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
