{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af8f51ba",
   "metadata": {},
   "source": [
    "Example taken from [https://towardsdatascience.com/question-answering-with-a-fine-tuned-bert-bc4dafd45626](https://towardsdatascience.com/question-answering-with-a-fine-tuned-bert-bc4dafd45626)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81f7e22a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50618375",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-02 16:06:53.789702: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import BertForQuestionAnswering\n",
    "from transformers import BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00da28b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# coqa = pd.read_json('http://downloads.cs.stanford.edu/nlp/data/coqa/coqa-train-v1.0.json')\n",
    "# coqa.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8355389c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# coqa.style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1fd80651",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #required columns in our dataframe\n",
    "# cols = [\"text\",\"question\",\"answer\"]\n",
    "# #list of lists to create our dataframe\n",
    "# comp_list = []\n",
    "# for index, row in coqa.iterrows():\n",
    "#     for i in range(len(row[\"data\"][\"questions\"])):\n",
    "#         temp_list = []\n",
    "#         temp_list.append(row[\"data\"][\"story\"])\n",
    "#         temp_list.append(row[\"data\"][\"questions\"][i][\"input_text\"])\n",
    "#         temp_list.append(row[\"data\"][\"answers\"][i][\"input_text\"])\n",
    "#         comp_list.append(temp_list)\n",
    "# new_df = pd.DataFrame(comp_list, columns=cols) \n",
    "# #saving the dataframe to csv file for further loading\n",
    "# new_df.to_csv(\"data/CoQA_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f23472f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Vatican Apostolic Library (), more commonl...</td>\n",
       "      <td>When was the Vat formally opened?</td>\n",
       "      <td>It was formally established in 1475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Vatican Apostolic Library (), more commonl...</td>\n",
       "      <td>what is the library for?</td>\n",
       "      <td>research</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Vatican Apostolic Library (), more commonl...</td>\n",
       "      <td>for what subjects?</td>\n",
       "      <td>history, and law</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Vatican Apostolic Library (), more commonl...</td>\n",
       "      <td>and?</td>\n",
       "      <td>philosophy, science and theology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Vatican Apostolic Library (), more commonl...</td>\n",
       "      <td>what was started in 2014?</td>\n",
       "      <td>a  project</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  The Vatican Apostolic Library (), more commonl...   \n",
       "1  The Vatican Apostolic Library (), more commonl...   \n",
       "2  The Vatican Apostolic Library (), more commonl...   \n",
       "3  The Vatican Apostolic Library (), more commonl...   \n",
       "4  The Vatican Apostolic Library (), more commonl...   \n",
       "\n",
       "                            question                               answer  \n",
       "0  When was the Vat formally opened?  It was formally established in 1475  \n",
       "1           what is the library for?                             research  \n",
       "2                 for what subjects?                     history, and law  \n",
       "3                               and?     philosophy, science and theology  \n",
       "4          what was started in 2014?                           a  project  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"data/CoQA_data.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e66783e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of question and answers:  108647\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of question and answers: \", len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63f5716d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertForQuestionAnswering.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fadf8d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_num = np.random.randint(0,len(data))\n",
    "question = data[\"question\"][random_num]\n",
    "text = data[\"text\"][random_num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5d9d6ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input has a total of 401 tokens.\n"
     ]
    }
   ],
   "source": [
    "input_ids = tokenizer.encode(question, text)\n",
    "print(\"The input has a total of {} tokens.\".format(len(input_ids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4def89cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "how                        2,129\n",
      "many                       2,116\n",
      "followers                  8,771\n",
      "did                        2,106\n",
      "they                       2,027\n",
      "have                       2,031\n",
      "in                         1,999\n",
      "2008                       2,263\n",
      "?                          1,029\n",
      "(                          1,006\n",
      "cnn                       13,229\n",
      ")                          1,007\n",
      "-                          1,011\n",
      "-                          1,011\n",
      "cnn                       13,229\n",
      "marked                     4,417\n",
      "a                          1,037\n",
      "milestone                 19,199\n",
      "monday                     6,928\n",
      ".                          1,012\n",
      "just                       2,074\n",
      "before                     2,077\n",
      "noon                      11,501\n",
      ",                          1,010\n",
      "the                        1,996\n",
      "@                          1,030\n",
      "cnn                       13,229\n",
      "##br                      19,892\n",
      "##k                        2,243\n",
      "account                    4,070\n",
      "topped                     9,370\n",
      "10                         2,184\n",
      "million                    2,454\n",
      "followers                  8,771\n",
      "on                         2,006\n",
      "twitter                   10,474\n",
      ".                          1,012\n",
      "that                       2,008\n",
      "puts                       8,509\n",
      "our                        2,256\n",
      "twitter                   10,474\n",
      "account                    4,070\n",
      "in                         1,999\n",
      "the                        1,996\n",
      "company                    2,194\n",
      "of                         1,997\n",
      "lady                       3,203\n",
      "gaga                      23,332\n",
      ",                          1,010\n",
      "president                  2,343\n",
      "barack                    13,857\n",
      "obama                      8,112\n",
      "and                        1,998\n",
      "cr                        13,675\n",
      "##ist                      2,923\n",
      "##iano                    15,668\n",
      "ronald                     8,923\n",
      "##o                        2,080\n",
      ".                          1,012\n",
      "to                         2,000\n",
      "mark                       2,928\n",
      "the                        1,996\n",
      "occasion                   6,686\n",
      ",                          1,010\n",
      "it                         2,009\n",
      "'                          1,005\n",
      "s                          1,055\n",
      "worth                      4,276\n",
      "reflecting                10,842\n",
      "how                        2,129\n",
      "we                         2,057\n",
      "got                        2,288\n",
      "here                       2,182\n",
      ".                          1,012\n",
      "the                        1,996\n",
      "first                      2,034\n",
      "t                          1,056\n",
      "##wee                     28,394\n",
      "##t                        2,102\n",
      "on                         2,006\n",
      "@                          1,030\n",
      "cnn                       13,229\n",
      "##br                      19,892\n",
      "##k                        2,243\n",
      "wasn                       2,347\n",
      "'                          1,005\n",
      "t                          1,056\n",
      "news                       2,739\n",
      ",                          1,010\n",
      "and                        1,998\n",
      "it                         2,009\n",
      "wasn                       2,347\n",
      "'                          1,005\n",
      "t                          1,056\n",
      "written                    2,517\n",
      "by                         2,011\n",
      "an                         2,019\n",
      "employee                   7,904\n",
      "of                         1,997\n",
      "cnn                       13,229\n",
      ".                          1,012\n",
      "\"                          1,000\n",
      "testing                    5,604\n",
      "\"                          1,000\n",
      "is                         2,003\n",
      "what                       2,054\n",
      "james                      2,508\n",
      "cox                        9,574\n",
      "t                          1,056\n",
      "##wee                     28,394\n",
      "##ted                      3,064\n",
      "in                         1,999\n",
      "january                    2,254\n",
      "2007                       2,289\n",
      ".                          1,012\n",
      "cox                        9,574\n",
      "said                       2,056\n",
      "he                         2,002\n",
      "started                    2,318\n",
      "the                        1,996\n",
      "account                    4,070\n",
      "as                         2,004\n",
      "a                          1,037\n",
      "way                        2,126\n",
      "to                         2,000\n",
      "receive                    4,374\n",
      "cnn                       13,229\n",
      "'                          1,005\n",
      "s                          1,055\n",
      "breaking                   4,911\n",
      "news                       2,739\n",
      "alert                      9,499\n",
      "##s                        2,015\n",
      "on                         2,006\n",
      "his                        2,010\n",
      "phone                      3,042\n",
      ".                          1,012\n",
      "the                        1,996\n",
      "account                    4,070\n",
      "started                    2,318\n",
      "to                         2,000\n",
      "grow                       4,982\n",
      "and                        1,998\n",
      "gain                       5,114\n",
      "attention                  3,086\n",
      ".                          1,012\n",
      "journalist                 4,988\n",
      "and                        1,998\n",
      "fellow                     3,507\n",
      "developer                  9,722\n",
      "brian                      4,422\n",
      "boyer                     23,456\n",
      "posted                     6,866\n",
      "this                       2,023\n",
      "to                         2,000\n",
      "his                        2,010\n",
      "blog                       9,927\n",
      "back                       2,067\n",
      "in                         1,999\n",
      "2008                       2,263\n",
      ":                          1,024\n",
      "\"                          1,000\n",
      "@                          1,030\n",
      "cnn                       13,229\n",
      "##br                      19,892\n",
      "##k                        2,243\n",
      "ain                        7,110\n",
      "'                          1,005\n",
      "t                          1,056\n",
      "cnn                       13,229\n",
      "but                        2,021\n",
      "with                       2,007\n",
      ">                          1,028\n",
      "30                         2,382\n",
      "##k                        2,243\n",
      "followers                  8,771\n",
      ",                          1,010\n",
      "he                         2,002\n",
      "owns                       8,617\n",
      "the                        1,996\n",
      "brand                      4,435\n",
      ".                          1,012\n",
      "\"                          1,000\n",
      "cox                        9,574\n",
      "wrote                      2,626\n",
      "a                          1,037\n",
      "response                   3,433\n",
      "to                         2,000\n",
      "that                       2,008\n",
      "post                       2,695\n",
      ":                          1,024\n",
      "\"                          1,000\n",
      "i                          1,045\n",
      "'                          1,005\n",
      "ve                         2,310\n",
      "been                       2,042\n",
      "in                         1,999\n",
      "contact                    3,967\n",
      "with                       2,007\n",
      "cnn                       13,229\n",
      "-                          1,011\n",
      "-                          1,011\n",
      "they                       2,027\n",
      "won                        2,180\n",
      "'                          1,005\n",
      "t                          1,056\n",
      "sue                        9,790\n",
      ",                          1,010\n",
      "i                          1,045\n",
      "'                          1,005\n",
      "m                          1,049\n",
      "fairly                     7,199\n",
      "sure                       2,469\n",
      ",                          1,010\n",
      "however                    2,174\n",
      "i                          1,045\n",
      "'                          1,005\n",
      "m                          1,049\n",
      "constantly                 7,887\n",
      "dealing                    7,149\n",
      "with                       2,007\n",
      "the                        1,996\n",
      "problem                    3,291\n",
      "of                         1,997\n",
      "confusion                  6,724\n",
      "-                          1,011\n",
      "-                          1,011\n",
      "users                      5,198\n",
      "still                      2,145\n",
      "think                      2,228\n",
      "that                       2,008\n",
      "@                          1,030\n",
      "cnn                       13,229\n",
      "##br                      19,892\n",
      "##k                        2,243\n",
      "is                         2,003\n",
      "an                         2,019\n",
      "official                   2,880\n",
      "feed                       5,438\n",
      ",                          1,010\n",
      "therefore                  3,568\n",
      "making                     2,437\n",
      "me                         2,033\n",
      "a                          1,037\n",
      "def                       13,366\n",
      "##act                     18,908\n",
      "##o                        2,080\n",
      "cnn                       13,229\n",
      "employee                   7,904\n",
      ",                          1,010\n",
      "which                      2,029\n",
      "is                         2,003\n",
      "a                          1,037\n",
      "problem                    3,291\n",
      ".                          1,012\n",
      "\"                          1,000\n",
      "we                         2,057\n",
      "didn                       2,134\n",
      "'                          1,005\n",
      "t                          1,056\n",
      "sue                        9,790\n",
      ",                          1,010\n",
      "but                        2,021\n",
      "we                         2,057\n",
      "did                        2,106\n",
      "work                       2,147\n",
      "out                        2,041\n",
      "a                          1,037\n",
      "deal                       3,066\n",
      "to                         2,000\n",
      "get                        2,131\n",
      "the                        1,996\n",
      "handle                     5,047\n",
      ".                          1,012\n",
      "as                         2,004\n",
      "we                         2,057\n",
      "celebrate                  8,439\n",
      "reaching                   4,285\n",
      "the                        1,996\n",
      "10                         2,184\n",
      "-                          1,011\n",
      "million                    2,454\n",
      "-                          1,011\n",
      "follower                  22,399\n",
      "mark                       2,928\n",
      ",                          1,010\n",
      "cox                        9,574\n",
      "is                         2,003\n",
      "the                        1,996\n",
      "first                      2,034\n",
      "person                     2,711\n",
      "we                         2,057\n",
      "should                     2,323\n",
      "thank                      4,067\n",
      ".                          1,012\n",
      "the                        1,996\n",
      "second                     2,117\n",
      "person                     2,711\n",
      "to                         2,000\n",
      "thank                      4,067\n",
      ",                          1,010\n",
      "naturally                  8,100\n",
      ",                          1,010\n",
      "is                         2,003\n",
      "ashton                    13,772\n",
      "ku                        13,970\n",
      "##tch                     10,649\n",
      "##er                       2,121\n",
      ".                          1,012\n",
      "in                         1,999\n",
      "2009                       2,268\n",
      ",                          1,010\n",
      "he                         2,002\n",
      "challenged                 8,315\n",
      "cnn                       13,229\n",
      "to                         2,000\n",
      "a                          1,037\n",
      "competition                2,971\n",
      "to                         2,000\n",
      "see                        2,156\n",
      "who                        2,040\n",
      "could                      2,071\n",
      "first                      2,034\n",
      "reach                      3,362\n",
      "1                          1,015\n",
      "million                    2,454\n",
      "followers                  8,771\n",
      ".                          1,012\n",
      "ku                        13,970\n",
      "##tch                     10,649\n",
      "##er                       2,121\n",
      "won                        2,180\n",
      ".                          1,012\n",
      "at                         2,012\n",
      "more                       2,062\n",
      "than                       2,084\n",
      "13                         2,410\n",
      "million                    2,454\n",
      "followers                  8,771\n",
      ",                          1,010\n",
      "@                          1,030\n",
      "ap                         9,706\n",
      "##lus                      7,393\n",
      "##k                        2,243\n",
      "is                         2,003\n",
      "still                      2,145\n",
      "in                         1,999\n",
      "the                        1,996\n",
      "lead                       2,599\n",
      ".                          1,012\n",
      "and                        1,998\n",
      "we                         2,057\n",
      "'                          1,005\n",
      "re                         2,128\n",
      "still                      2,145\n",
      "coming                     2,746\n",
      "after                      2,044\n",
      "him                        2,032\n",
      ".                          1,012\n",
      "we                         2,057\n",
      "have                       2,031\n",
      "a                          1,037\n",
      "simple                     3,722\n",
      "approach                   3,921\n",
      "to                         2,000\n",
      "@                          1,030\n",
      "cnn                       13,229\n",
      "##br                      19,892\n",
      "##k                        2,243\n",
      ",                          1,010\n",
      "and                        1,998\n",
      "we                         2,057\n",
      "believe                    2,903\n",
      "that                       2,008\n",
      "'                          1,005\n",
      "s                          1,055\n",
      "one                        2,028\n",
      "of                         1,997\n",
      "the                        1,996\n",
      "keys                       6,309\n",
      "to                         2,000\n",
      "its                        2,049\n",
      "success                    3,112\n",
      ".                          1,012\n",
      "breaking                   4,911\n",
      "news                       2,739\n",
      ",                          1,010\n",
      "from                       2,013\n",
      "an                         2,019\n",
      "organization               3,029\n",
      "that                       2,008\n",
      "built                      2,328\n",
      "its                        2,049\n",
      "brand                      4,435\n",
      "on                         2,006\n",
      "breaking                   4,911\n",
      "news                       2,739\n",
      ".                          1,012\n",
      "straight                   3,442\n",
      "up                         2,039\n",
      ".                          1,012\n"
     ]
    }
   ],
   "source": [
    "tokens = tokenizer.convert_ids_to_tokens(input_ids)\n",
    "for token, id in zip(tokens, input_ids):\n",
    "    print('{:16}{:16,}'.format(token,id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d2d4c7a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "102 is not in list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/np/9gry61813j75vjzz9d0txhcc0000gn/T/ipykernel_7593/135244258.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#first occurence of [SEP] token\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msep_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msep_token_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"SEP token index: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#number of tokens in segment A (question) - this will be one more than the sep_idx as the index in Python starts from 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mnum_seg_a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msep_idx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: 102 is not in list"
     ]
    }
   ],
   "source": [
    "#first occurence of [SEP] token\n",
    "sep_idx = input_ids.index(tokenizer.sep_token_id)\n",
    "print(\"SEP token index: \", sep_idx)\n",
    "#number of tokens in segment A (question) - this will be one more than the sep_idx as the index in Python starts from 0\n",
    "num_seg_a = sep_idx+1\n",
    "print(\"Number of tokens in segment A: \", num_seg_a)\n",
    "#number of tokens in segment B (text)\n",
    "num_seg_b = len(input_ids) - num_seg_a\n",
    "print(\"Number of tokens in segment B: \", num_seg_b)\n",
    "#creating the segment ids\n",
    "segment_ids = [0]*num_seg_a + [1]*num_seg_b\n",
    "#making sure that every input token has a segment id\n",
    "assert len(segment_ids) == len(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f497b4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'segment_ids' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/np/9gry61813j75vjzz9d0txhcc0000gn/T/ipykernel_6598/345096721.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#token input_ids to represent the input and token segment_ids to differentiate our segments - question and text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msegment_ids\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'segment_ids' is not defined"
     ]
    }
   ],
   "source": [
    "#token input_ids to represent the input and token segment_ids to differentiate our segments - question and text\n",
    "output = model(torch.tensor([input_ids]),  token_type_ids=torch.tensor([segment_ids]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c412a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Question:\n",
      "When did the vita get released in the us?\n",
      "\n",
      "Answer:\n",
      "2005.\n"
     ]
    }
   ],
   "source": [
    "#tokens with highest start and end scores\n",
    "answer_start = torch.argmax(output.start_logits)\n",
    "answer_end = torch.argmax(output.end_logits)\n",
    "if answer_end >= answer_start:\n",
    "    answer = \" \".join(tokens[answer_start:answer_end+1])\n",
    "else:\n",
    "    print(\"I am unable to find the answer to this question. Can you please ask another question?\")\n",
    "    \n",
    "print(\"\\nQuestion:\\n{}\".format(question.capitalize()))\n",
    "print(\"\\nAnswer:\\n{}.\".format(answer.capitalize()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8281235",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'answer_start' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/np/9gry61813j75vjzz9d0txhcc0000gn/T/ipykernel_6598/3420395214.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0manswer_start\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer_start\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manswer_end\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"##\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'answer_start' is not defined"
     ]
    }
   ],
   "source": [
    "answer = tokens[answer_start]\n",
    "for i in range(answer_start+1, answer_end+1):\n",
    "    if tokens[i][0:2] == \"##\":\n",
    "        answer += tokens[i][2:]\n",
    "    else:\n",
    "        answer += \" \" + tokens[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68148ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def question_answer(question, text):\n",
    "    \n",
    "    #tokenize question and text as a pair\n",
    "    input_ids = tokenizer.encode(question, text)\n",
    "    \n",
    "    #string version of tokenized ids\n",
    "    tokens = tokenizer.convert_ids_to_tokens(input_ids)\n",
    "    \n",
    "    #segment IDs\n",
    "    #first occurence of [SEP] token\n",
    "    sep_idx = input_ids.index(tokenizer.sep_token_id)\n",
    "    #number of tokens in segment A (question)\n",
    "    num_seg_a = sep_idx+1\n",
    "    #number of tokens in segment B (text)\n",
    "    num_seg_b = len(input_ids) - num_seg_a\n",
    "    \n",
    "    #list of 0s and 1s for segment embeddings\n",
    "    segment_ids = [0]*num_seg_a + [1]*num_seg_b\n",
    "    assert len(segment_ids) == len(input_ids)\n",
    "    \n",
    "    #model output using input_ids and segment_ids\n",
    "    output = model(torch.tensor([input_ids]), token_type_ids=torch.tensor([segment_ids]))\n",
    "    \n",
    "    #reconstructing the answer\n",
    "    answer_start = torch.argmax(output.start_logits)\n",
    "    answer_end = torch.argmax(output.end_logits)\n",
    "    if answer_end >= answer_start:\n",
    "        answer = tokens[answer_start]\n",
    "        for i in range(answer_start+1, answer_end+1):\n",
    "            if tokens[i][0:2] == \"##\":\n",
    "                answer += tokens[i][2:]\n",
    "            else:\n",
    "                answer += \" \" + tokens[i]\n",
    "                \n",
    "    if answer.startswith(\"[CLS]\"):\n",
    "        answer = \"Unable to find the answer to your question.\"\n",
    "    \n",
    "    print(\"\\nPredicted answer for '{0}':\\n{1}\".format(question,answer.capitalize()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ca11a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicted answer for 'Where was the Auction held?':\n",
      "Hard rock cafe in new york ' s times square\n",
      "Original answer:\n",
      " Hard Rock Cafe\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"\n",
    "New York (CNN) -- More than 80 Michael Jackson collectibles -- including the late pop star's famous rhinestone-studded \n",
    "glove from a 1983 performance -- were auctioned off Saturday, reaping a total $2 million. Profits from the auction at \n",
    "the Hard Rock Cafe in New York's Times Square crushed pre-sale expectations of only $120,000 in sales. The highly \n",
    "prized memorabilia, which included items spanning the many stages of Jackson's career, came from more than 30 fans, \n",
    "associates and family members, who contacted Julien's Auctions to sell their gifts and mementos of the singer. \n",
    "Jackson's flashy glove was the big-ticket item of the night, fetching $420,000 from a buyer in Hong Kong, China. \n",
    "Jackson wore the glove at a 1983 performance during \\\"Motown 25,\\\" an NBC special where he debuted his revolutionary \n",
    "moonwalk. Fellow Motown star Walter \\\"Clyde\\\" Orange of the Commodores, who also performed in the special 26 years \n",
    "ago, said he asked for Jackson's autograph at the time, but Jackson gave him the glove instead. \"The legacy that \n",
    "[Jackson] left behind is bigger than life for me,\\\" Orange said. \\\"I hope that through that glove people can see what \n",
    "he was trying to say in his music and what he said in his music.\\\" Orange said he plans to give a portion of the \n",
    "proceeds to charity. Hoffman Ma, who bought the glove on behalf of Ponte 16 Resort in Macau, paid a 25 percent buyer's \n",
    "premium, which was tacked onto all final sales over $50,000. Winners of items less than $50,000 paid a 20 percent premium.\n",
    "\"\"\"\n",
    "question = \"Where was the Auction held?\"\n",
    "question_answer(question, text)\n",
    "#original answer from the dataset\n",
    "print(\"Original answer:\\n\", data.loc[data[\"question\"] == question][\"answer\"].values[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2db4b6-0fa8-4c6b-a67c-11f306e00afc",
   "metadata": {},
   "source": [
    "News taken from [https://www.swissinfo.ch/eng/anti-vax-protesters-in-rome-target-draghi-s-office--union-s-headquarters/47015884](https://www.swissinfo.ch/eng/anti-vax-protesters-in-rome-target-draghi-s-office--union-s-headquarters/47015884)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5366d2-97ce-4c93-af2e-3841117cab5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicted answer for 'Is green pass only digital?':\n",
      "A digital or paper certificate showing someone has received at least one vaccine dose , has tested negative or recently recovered from the virus\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"\n",
    "Anti-vax protesters in Rome target Draghi's office, union's headquarters.\n",
    "\n",
    "Italian police used water cannon and tear gas on Saturday to push back hundreds of people, including \n",
    "neo-fascist activists, demonstrating in Rome against a government drive to make the COVID-19 \"Green Pass\" \n",
    "mandatory for all workers.\n",
    "One group of protesters tried to break through police lines to reach Prime Minister Mario Draghi's city centre \n",
    "office, while a separate group tried to smash their way into the headquarters of Italy's main CGIL trade union.\n",
    "The protests come days before Italy becomes the first country in Europe to make all workers carry the \n",
    "Green Pass in an effort to accelerate vaccinations and stamp out coronavirus infections.\n",
    "The pass, a digital or paper certificate showing someone has received at least one vaccine dose, has tested \n",
    "negative or recently recovered from the virus, was originally conceived to ease travel among European Union states.\n",
    "Draghi denounced Saturday's violence and said his broad unity government remained committed to completing its \n",
    "vaccination campaign.\n",
    "\"The right to demonstrate to support one's ideas can never degenerate into acts of aggression and intimidation,\" \n",
    "he said in a statement issued by his office.\n",
    "Opponents of the Green Pass say it tramples on freedoms and is a back-door means of forcing people to vaccinate. \n",
    "Their cause has been backed by far-right neo-fascist groups who local politicians accused of \n",
    "orchestrating Saturday's violence.\n",
    "Local media reported that around 10,000 people took to the streets of the Italian capital, with many \n",
    "chanting \"freedom, freedom\" as some looked to break past police in riot gear deployed to guard access \n",
    "to Draghi's office.\n",
    "CGIL, which has accepted the Green Pass system for workers, condemned the attack on its offices.\n",
    "\"The assault on CGIL's national headquarters is an act of fascist thuggery, an attack on democracy and on \n",
    "the world of work,\" its leader Maurizio Landini said in a statement. \"No-one should think that they can return \n",
    "our country to its fascist past.\n",
    "\"\"\"\n",
    "question = \"Is green pass only digital?\"\n",
    "question_answer(question, text)\n",
    "#NO original answer from the dataset - OUT OF SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25254e5b-957a-4769-85d5-0ae73743a089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicted answer for 'Who is Draghi?':\n",
      "Prime minister\n"
     ]
    }
   ],
   "source": [
    "question = \"Who is Draghi?\"\n",
    "question_answer(question, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8755667d-5ac4-4332-8a07-49e817367345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicted answer for 'Why people attacked the trade union?':\n",
      "Fascist thuggery\n"
     ]
    }
   ],
   "source": [
    "question = \"Why people attacked the trade union?\"\n",
    "question_answer(question, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991369d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicted answer for 'What's the name of the trade union attacked?':\n",
      "Cgil\n"
     ]
    }
   ],
   "source": [
    "question = \"What's the name of the trade union attacked?\"\n",
    "question_answer(question, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ce1999-fa6a-4caa-b26f-129798abba51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicted answer for 'Why is the green pass an attack to freedom?':\n",
      "It tramples on freedoms and is a back - door means of forcing people to vaccinate\n"
     ]
    }
   ],
   "source": [
    "question = \"Why is the green pass an attack to freedom?\"\n",
    "question_answer(question, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9deeb8ab-4cfb-4b11-b4d5-59d7a96f14af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49d06d6-3581-4fb3-a83b-997c953eec88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cd2f9d5a-a78a-455d-a614-8d966a96ec24",
   "metadata": {},
   "source": [
    "Another Example\n",
    "\n",
    "from [https://www.britannica.com/topic/The-Old-Man-and-the-Sea-novel-by-Hemingway](https://www.britannica.com/topic/The-Old-Man-and-the-Sea-novel-by-Hemingway)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f0f3c8-a69f-4ce4-8944-a623eae6147a",
   "metadata": {},
   "outputs": [],
   "source": [
    "text2 = \"\"\"\n",
    "The Old Man and the Sea, short heroic novel by Ernest Hemingway, published in 1952 and awarded the 1953 \n",
    "Pulitzer Prize for fiction. It was his last major work of fiction. The story centres on an aging fisherman \n",
    "who engages in an epic battle to catch a giant marlin.\n",
    "\n",
    "The central character is an old Cuban fisherman named Santiago, who has not caught a fish for 84 days. \n",
    "The family of his apprentice, Manolin, has forced the boy to leave the old fisherman, though Manolin \n",
    "continues to support him with food and bait. Santiago is a mentor to the boy, who cherishes the old man and \n",
    "the life lessons he imparts. Convinced that his luck must change, Santiago takes his skiff far out into \n",
    "the deep waters of the Gulf Stream, where he soon hooks a giant marlin. With all his great experience \n",
    "and strength, he struggles with the fish for three days, admiring its strength, dignity, and faithfulness \n",
    "to its identity; its destiny is as true as Santiagoâ€™s as a fisherman. He finally reels the marlin in and \n",
    "lashes it to his boat.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a447b8-4c02-48ba-b14c-dbf28b48090f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicted answer for 'What is the story called?':\n",
      "The old man and the sea\n",
      "\n",
      "Predicted answer for 'What is the story about?':\n",
      "An aging fisherman who engages in an epic battle to catch a giant marlin\n"
     ]
    }
   ],
   "source": [
    "question2a = \"What is the story called?\"\n",
    "question_answer(question2a, text2)\n",
    "\n",
    "question2b = \"What is the story about?\"\n",
    "question_answer(question2b, text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7def12c1-8950-439a-8e37-27cde85ef409",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicted answer for 'What was his last work of fiction?':\n",
      "The old man and the sea\n",
      "\n",
      "Predicted answer for 'What was her last work of fiction?':\n",
      "The old man and the sea\n"
     ]
    }
   ],
   "source": [
    "question2c = \"What was his last work of fiction?\"\n",
    "question_answer(question2c, text2)\n",
    "\n",
    "question2d = \"What was her last work of fiction?\"\n",
    "question_answer(question2d, text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24c22c4-c921-4446-af49-61e3fcd75966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicted answer for 'What is the size of the universe according to Hemingway?':\n",
      "84 days\n"
     ]
    }
   ],
   "source": [
    "question2e = \"What is the size of the universe according to Hemingway?\"\n",
    "question_answer(question2e, text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c43442b-5f8e-49ac-95e7-5ab99a1082a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicted answer for 'What is the age of the universe?':\n",
      "84 days\n"
     ]
    }
   ],
   "source": [
    "question2f = \"What is the age of the universe?\"\n",
    "question_answer(question2f, text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ac76d1-fa1a-4b2b-8553-ac49304565b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicted answer for 'Why is Manolin supporting Santiago?':\n",
      "Food and bait\n"
     ]
    }
   ],
   "source": [
    "question2g = \"Why is Manolin supporting Santiago?\"\n",
    "question_answer(question2g, text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60bafd51-d36e-49b6-8090-a5db66c18956",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "83dc1a58-9bcd-44cb-81c9-55c9b3592019",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'BlenderbotTokenizer' from 'transformers' (/Users/davebrunner/opt/anaconda3/lib/python3.8/site-packages/transformers/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/np/9gry61813j75vjzz9d0txhcc0000gn/T/ipykernel_7593/1616987759.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#tokenizer = BlenderbotSmallTokenizer.from_pretrained(mname)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBlenderbotTokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBlenderbotForConditionalGeneration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;31m#mname = 'facebook/blenderbot-90M'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mmname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'facebook/blenderbot-400M-distill'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'BlenderbotTokenizer' from 'transformers' (/Users/davebrunner/opt/anaconda3/lib/python3.8/site-packages/transformers/__init__.py)"
     ]
    }
   ],
   "source": [
    "#from transformers import BlenderbotSmallTokenizer, BlenderbotSmallForConditionalGeneration\n",
    "#mname = 'facebook/blenderbot_small-90M'\n",
    "#model = BlenderbotSmallForConditionalGeneration.from_pretrained(mname)\n",
    "#tokenizer = BlenderbotSmallTokenizer.from_pretrained(mname)\n",
    "\n",
    "from transformers import BlenderbotTokenizer, BlenderbotForConditionalGeneration\n",
    "#mname = 'facebook/blenderbot-90M'\n",
    "mname = 'facebook/blenderbot-400M-distill'\n",
    "#mname = 'facebook/blenderbot-1B-distill'\n",
    "#mname = 'facebook/blenderbot-3B' \n",
    "model = BlenderbotForConditionalGeneration.from_pretrained(mname)\n",
    "tokenizer = BlenderbotTokenizer.from_pretrained(mname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a9042e-5a71-4cac-b27d-0cbd61df1e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrap_interaction(entry):\n",
    "    return \"<s>\"+entry+\"</s>\"\n",
    "\n",
    "def interact_with_BOT(interaction, query):\n",
    "    print(\"Previous interactions: \")\n",
    "    nr = int(interaction.count('</s>')/2)\n",
    "    if (nr > 0):\n",
    "        for i in interaction.split(\"</s><s>\"):\n",
    "            print(\" --> \"+i.replace(\"<s>\",\"\").replace(\"</s>\",\"\")) \n",
    "    else:\n",
    "        print(\"--- NONE ---\")\n",
    "    print(\"Interaction #{}\".format(nr+1))\n",
    "    print(\" Human: \", query)\n",
    "    interaction += wrap_interaction(query)\n",
    "    inputs = tokenizer([interaction], return_tensors='pt')\n",
    "    next_reply_ids = model.generate(**inputs)\n",
    "    reply = tokenizer.batch_decode(next_reply_ids, skip_special_tokens=True)[0]\n",
    "    print(\" Bot: \", reply)\n",
    "    interaction += wrap_interaction(reply) \n",
    "    return interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a828ab-86e5-41ec-93a4-e8105b5fb4a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous interactions: \n",
      "--- NONE ---\n",
      "Interaction #1\n",
      " Human:  My dad is not answering\n",
      " Bot:   I'm sorry to hear that. I hope he comes back soon. What's going on?\n"
     ]
    }
   ],
   "source": [
    "step0 = interact_with_BOT(\"\",\"My dad is not answering\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e48999-defa-49b1-b7e3-fa0b4640fc1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous interactions: \n",
      " --> My dad is not answering\n",
      " -->  I'm sorry to hear that. I hope he comes back soon. What's going on?\n",
      "Interaction #2\n",
      " Human:  No, he seems to be unconscious...\n",
      " Bot:   I don't know what to do. I feel like I'm going to have to call the police.\n"
     ]
    }
   ],
   "source": [
    "step1 = interact_with_BOT(step0,\"No, he seems to be unconscious...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1855035d-8af2-49ec-8d37-283cf1a84102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous interactions: \n",
      " --> My dad is not answering\n",
      " -->  I'm sorry to hear that. I hope he comes back soon. What's going on?\n",
      " --> No, he seems to be unconscious...\n",
      " -->  I don't know what to do. I feel like I'm going to have to call the police.\n",
      "Interaction #3\n",
      " Human:  This is the issue... Can you think about something else, maybe?\n",
      " Bot:   I can't think of anything else at the moment. I just want him to come home.\n"
     ]
    }
   ],
   "source": [
    "step2 = interact_with_BOT(step1,\"This is the issue... Can you think about something else, maybe?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853f2f68-0e8e-4663-86ce-0d5a7762c2ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df0bb99-29bf-4e84-a5e8-2a231a7b4d6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous interactions: \n",
      "--- NONE ---\n",
      "Interaction #1\n",
      " Human:  My PC does not start up\n",
      " Bot:   I'm sorry to hear that. I hope it gets fixed soon. What's wrong with it?\n"
     ]
    }
   ],
   "source": [
    "step0 = interact_with_BOT(\"\",\"My PC does not start up\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fba5190-96d9-4fd0-8682-cc535e203960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous interactions: \n",
      " --> My PC does not start up\n",
      " -->  I'm sorry to hear that. I hope it gets fixed soon. What's wrong with it?\n",
      "Interaction #2\n",
      " Human:  I think the reson is the operating system\n",
      " Bot:   I am not sure what is wrong. I am going to have to take it in to get it fixed.\n"
     ]
    }
   ],
   "source": [
    "step1 = interact_with_BOT(step0,\"I think the reson is the operating system\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e612e5d6-9282-4b42-87b5-088cdc9e34ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous interactions: \n",
      " --> My PC does not start up\n",
      " -->  I'm sorry to hear that. I hope it gets fixed soon. What's wrong with it?\n",
      " --> I think the reson is the operating system\n",
      " -->  I am not sure what is wrong. I am going to have to take it in to get it fixed.\n",
      "Interaction #3\n",
      " Human:  What operating system do you think it has?\n",
      " Bot:   I don't know, but it's been acting up for a few days now.\n"
     ]
    }
   ],
   "source": [
    "step2 = interact_with_BOT(step1,\"What operating system do you think it has?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aafcd72c-9c17-4f00-b5e7-0667cbc82e7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous interactions: \n",
      " --> My PC does not start up\n",
      " -->  I'm sorry to hear that. I hope it gets fixed soon. What's wrong with it?\n",
      " --> I think the reson is the operating system\n",
      " -->  I am not sure what is wrong. I am going to have to take it in to get it fixed.\n",
      " --> What operating system do you think it has?\n",
      " -->  I don't know, but it's been acting up for a few days now.\n",
      "Interaction #4\n",
      " Human:  I don't want to leave my PC here...\n",
      " Bot:   That's too bad.  I hope you can get it sorted out soon.\n"
     ]
    }
   ],
   "source": [
    "step3 = interact_with_BOT(step2,\"I don't want to leave my PC here...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece0138e-934d-4547-b31b-1f0757b17698",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
